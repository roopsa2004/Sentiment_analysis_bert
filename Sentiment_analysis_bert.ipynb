{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roopsa2004/Sentiment_analysis_bert/blob/main/Sentiment_analysis_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA520KES6oAV"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6rjrYhndlSp"
      },
      "outputs": [],
      "source": [
        "# Use IMDB dataset as an alternative\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHDBwnf_efTB"
      },
      "outputs": [],
      "source": [
        "# Load the IMDB dataset (already balanced between positive and negative)\n",
        "imdb = load_dataset(\"imdb\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to pandas DataFrame\n",
        "train_data = pd.DataFrame({\n",
        "    'text': imdb['train']['text'],\n",
        "    'sentiment': imdb['train']['label']  # 0 is negative, 1 is positive\n",
        "})"
      ],
      "metadata": {
        "id": "p-FoBODuEMNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlS712fJeurl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbhH8-wSe_5E"
      },
      "outputs": [],
      "source": [
        "# Clean the text data\n",
        "def clean_text(text):\n",
        "  # Check if text is a string, otherwise convert it to string\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
        "    text = re.sub(r'#', '', text)  # Remove hashtag symbol\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "train_data['cleaned_text'] = train_data['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class balance\n",
        "print(\"IMDB dataset sentiment distribution:\")\n",
        "print(train_data['sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "FbZBfb_8ErwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    train_data['cleaned_text'],\n",
        "    train_data['sentiment'],\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=train_data['sentiment']\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Verify splits have both classes\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\nValidation set class distribution:\")\n",
        "print(pd.Series(y_val).value_counts())\n",
        "print(\"\\nTest set class distribution:\")\n",
        "print(pd.Series(y_test).value_counts())\n"
      ],
      "metadata": {
        "id": "0gNJtJsQE-sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt4D4WNsfT1s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.optim import AdamW # Import AdamW from torch.optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2xL6_tdfm6R"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx])\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fZBQk5-f0ob"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, n_classes=2):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop1 = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 256)\n",
        "        self.drop2 = nn.Dropout(p=0.3)\n",
        "        self.fc2 = nn.Linear(256, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.drop1(pooled_output)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.drop2(x)\n",
        "        return self.fc2(x)\n",
        "        # Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SentimentDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = SentimentDataset(X_val, y_val, tokenizer)\n",
        "test_dataset = SentimentDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "# Initialize the model\n",
        "model = SentimentClassifier()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60psbPxTgFVs"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # Import ReduceLROnPlateau\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, epochs=4):\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.5)\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            train_loss += loss.item()\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        predictions = []\n",
        "        actual_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Get predictions\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "                 # Store predictions and true labels\n",
        "                predictions.extend(preds.cpu().tolist())\n",
        "                actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        accuracy = accuracy_score(actual_labels, predictions)\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {accuracy:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        # Add the labels parameter to classification_report\n",
        "        print(classification_report(actual_labels, predictions, labels=np.unique(actual_labels), target_names=['Negative', 'Positive']))\n",
        "\n",
        "        # Save best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            torch.save(model.state_dict(), 'best_sentiment_model.pth')\n",
        "            print(f\"Best model saved with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "            # Train the model\n",
        "train_model(model, train_loader, val_loader, epochs=4)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_sentiment_model.pth'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFJcwQjggk6Y"
      },
      "outputs": [],
      "source": [
        "#Evaluate on test set\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            # Store predictions and labels\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(actual_labels, predictions)\n",
        "\n",
        "    print(f\"\\nTest accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(actual_labels, predictions, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ5nRknPgsJn"
      },
      "outputs": [],
      "source": [
        "# Function to predict sentiment for new texts\n",
        "def predict_sentiment(text, model, tokenizer):\n",
        "    # Clean the text\n",
        "    text = clean_text(text)\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    # Move to device\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, prediction = torch.max(outputs, dim=1)\n",
        "\n",
        "    sentiment_label = \"Positive\" if prediction.item() == 1 else \"Negative\"\n",
        "    return sentiment_label\n",
        "    # Test with some examples\n",
        "test_texts = [\n",
        "    \"I absolutely love this product! It's amazing!\",\n",
        "    \"This was a terrible experience, I'm very disappointed.\",\n",
        "    \"The service was okay, nothing special.\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    sentiment = predict_sentiment(text, model, tokenizer)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {sentiment}\\n\")"
      ]
    }
  ]
}